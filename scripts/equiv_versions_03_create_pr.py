#!/usr/bin/env python3
"""
Starting from versions_02_check_new_equiv.py results,
create a PR that adds missing equivalent releases to `results.json`
in the *it-fse-accreditati* repository.
"""

import os
import sys
import json
import base64
import glob
from collections import OrderedDict
from typing import Tuple
import pandas as pd
import requests
from pathlib import Path
from pprint import pprint

# ------------------- Configuration -------------------
REPO_OWNER = "ministero-salute"
REPO_NAME = "it-fse-accreditati"
RESULTS_JSON_PATH = "RESULTS/results.json"
BASE_BRANCH = "main"
PR_BRANCH_PREFIX = "add-missing-equivalents-"
PR_TITLE = "Add missing equivalent releases to results.json"
PR_BODY_TEMPLATE = (
    "This PR adds the missing `equiv_releases` entries detected by "
    "`versions_check_new_equiv.py`.\n\n"
    "The script reads the CSV generated by that check and updates the "
    "`equiv_releases` field for each matching vendor-application-version "
    "tuple, creating the list when it does not exist."
)
# -----------------------------------------------------

# ----------------------------------------------------------------------
# Helper that talks to GitHub
# ----------------------------------------------------------------------
def gh_api(url: str, method: str = "GET", **kwargs):
    token = os.getenv("GITHUB_TOKEN_IT_FSE_ACCREDITATI_PR_WRITE")
    if not token:
        raise EnvironmentError("Set GITHUB_TOKEN_IT_FSE_ACCREDITATI_PR_WRITE env-var with a PAT.")
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json",
    }
    resp = requests.request(method, f"https://api.github.com{url}", headers=headers, **kwargs)
    if not resp.ok:
        # Show GitHubâ€™s error payload for easier debugging
        try:
            err = resp.json()
        except Exception:
            err = resp.text
        raise RuntimeError(f"GitHub API error {resp.status_code}: {err}")
    return resp.json()


# ----------------------------------------------------------------------
# Get the **latest commit SHA** of the base branch (not the file SHA)
# ----------------------------------------------------------------------
def get_branch_commit_sha(branch: str) -> str:
    """
    Return the SHA of the tip commit of *branch* (e.g. ``main``).
    """
    data = gh_api(f"/repos/{REPO_OWNER}/{REPO_NAME}/git/refs/heads/{branch}")
    return data["object"]["sha"]


# ----------------------------------------------------------------------
# Keep the original function for reading the file
# ----------------------------------------------------------------------
def get_file_content(branch: str) -> dict:
    """Return the decoded JSON content of ``results.json`` on *branch*."""
    data = gh_api(
        f"/repos/{REPO_OWNER}/{REPO_NAME}/contents/{RESULTS_JSON_PATH}",
        params={"ref": branch},
    )
    content = base64.b64decode(data["content"]).decode()
    # Load using OrderedDict to keep original key/object order
    return json.loads(content, object_pairs_hook=OrderedDict)


# ----------------------------------------------------------------------
# Create a **new branch** - now using the commit SHA
# ----------------------------------------------------------------------
def create_branch(new_branch: str, base_commit_sha: str):
    """
    Create ``new_branch`` that points to ``base_commit_sha``.
    If the branch already exists we simply reuse it (GitHub will return 422;
    we catch that and ignore - the subsequent commit will fast-forward it).
    """
    try:
        gh_api(
            f"/repos/{REPO_OWNER}/{REPO_NAME}/git/refs",
            method="POST",
            json={"ref": f"refs/heads/{new_branch}", "sha": base_commit_sha},
        )
        print(f"ðŸŒ¿ Created branch `{new_branch}`")
    except RuntimeError as e:
        # 422 means the ref already exists - thatâ€™s fine, weâ€™ll push on it.
        if "Reference already exists" in str(e):
            print(f"âš ï¸ Branch `{new_branch}` already exists - re-using it.")
        else:
            raise


# ----------------------------------------------------------------------
# Commit the updated ``results.json`` to the new branch
# ----------------------------------------------------------------------
def commit_file(branch: str, file_sha: str, new_content: str, commit_msg: str):
    """Create a new commit on *branch* that updates results.json."""
    gh_api(
        f"/repos/{REPO_OWNER}/{REPO_NAME}/contents/{RESULTS_JSON_PATH}",
        method="PUT",
        json={
            "message": commit_msg,
            "content": base64.b64encode(new_content.encode()).decode(),
            "branch": branch,
            # ``sha`` must be the SHA of the *current* file version.
            # We reuse the SHA we already fetched when we read the file.
            "sha": file_sha, #base_commit_sha,
        },
    )
    print(f"ðŸ“¦ Committed updated {RESULTS_JSON_PATH} on `{branch}`")


# ----------------------------------------------------------------------
# Update results.json in place
# ----------------------------------------------------------------------
def update_results_json(results: dict, csv_path: str) -> Tuple[dict, dict]:
    df = pd.read_csv(csv_path, dtype=str).fillna("")
    df["vendor_lc"] = df["Vendor"].str.lower().str.strip()
    df["app_id_lc"] = df["App ID"].str.lower().str.strip()
    df["version_lc"] = df["Main Version"].str.lower().str.strip()

    miss_lookup = {
        (row.vendor_lc, row.app_id_lc, row.version_lc): [
            v.strip()
            for v in str(row.missing_equivalents).split(",")
            if v.strip()
        ]
        for row in df.itertuples()
    }

    for entry in results.get("results", []):
        v = entry.get("vendor", "").lower().strip()
        a = entry.get("application_id", "").lower().strip()
        ver = str(entry.get("version", "")).lower().strip()
        key = (v, a, ver)

        if key in miss_lookup:
            missing = miss_lookup[key]

            current = entry.get("equiv_releases") or []
            if not isinstance(current, list):
                current = list(current)

            merged = {str(x).lower(): x for x in current}
            for m in missing:
                merged[m.lower()] = m
            entry["equiv_releases"] = list(merged.values())
    return results, miss_lookup


def open_pr(head: str, base: str, title: str, body: str):
    gh_api(
        f"/repos/{REPO_OWNER}/{REPO_NAME}/pulls",
        method="POST",
        json={"title": title, "head": head, "base": base, "body": body},
    )
    print(f"ðŸ”€ PR opened: {title} (head={head} â†’ base={base})")


def main(csv_path: str | None = None):
    # ------------------- pick CSV -------------------
    if csv_path is None:
        candidate_files = glob.glob("comparison/missing_equivalents_*.csv")
        if not candidate_files:
            raise FileNotFoundError(
                "No CSV report found under 'comparison/'. Run the checker first or pass a CSV path."
            )
        csv_path = max(candidate_files)
        print(f"ðŸ”Ž No CSV argument supplied - using latest report: {csv_path}")

    # ------------------- fetch repo data -------------------
    base_commit_sha = get_branch_commit_sha(BASE_BRANCH)
    original_json = get_file_content(BASE_BRANCH)
    with open("results_original.json", "w", encoding="utf-8") as f:
        json.dump(original_json, f, indent=4, ensure_ascii=False)
    print("ðŸ’¾ Saved original results.json to ./results_original.json")


    # ------------------- update JSON -------------------
    updated_json, added_versions = update_results_json(original_json, csv_path) # attenzione che Ã¨ inplace in realtÃ 
    with open("results_updated.json", "w", encoding="utf-8") as f:
        json.dump(updated_json, f, indent=4, ensure_ascii=False)
    print("ðŸ’¾ Saved updated results.json to ./results_updated.json")
    pprint(added_versions)


    # ------------------- create branch & commit -------------------
    branch_name = PR_BRANCH_PREFIX + Path(csv_path).stem
    create_branch(branch_name, base_commit_sha)
    commit_msg = "feat: add missing equiv_releases entries"
    file_info = gh_api(
        f"/repos/{REPO_OWNER}/{REPO_NAME}/contents/{RESULTS_JSON_PATH}",
        params={"ref": BASE_BRANCH},
    )
    file_sha = file_info["sha"]
    commit_file(
        branch_name,
        file_sha, # SHA of the current file version
        json.dumps(updated_json, indent=4, ensure_ascii=False),
        commit_msg,
    )

    # ------------------- open PR -------------------
    # Convert the tuple-keyed dict into a JSON-serialisable list
    added_versions_list = [
        {
            "vendor": key[0],
            "app_id": key[1],
            "version": key[2],
            "missing": value,
        }
        for key, value in added_versions.items()
    ]
    added_versions_str = json.dumps(added_versions_list, indent=2, ensure_ascii=False)
    pr_body = f"{PR_BODY_TEMPLATE}\n\n**Added versions:**\n```json\n{added_versions_str}\n```"
    open_pr(branch_name, BASE_BRANCH, PR_TITLE, pr_body)


if __name__ == "__main__":
    # ------------------------------------------------------------------
    # Usage:
    #   python add_missing_equivalents_pr.py                # auto-pick latest CSV
    #   python add_missing_equivalents_pr.py path/to.csv    # explicit CSV
    # ------------------------------------------------------------------
    if len(sys.argv) > 2:
        print("Usage: python add_missing_equivalents_pr.py [optional_csv_path]")
        sys.exit(1)

    explicit_path = sys.argv[1] if len(sys.argv) == 2 else None
    main(explicit_path)